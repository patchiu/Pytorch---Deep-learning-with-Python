{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net()\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The torch.nn import gives us access to some helpful neural network things, such as various neural network layer types (things like regular fully-connected layers, convolutional layers (for imagery), recurrent layers...etc). For now, we've only spoken about fully-connected layers, so we will just be using those for now.\n",
    "\n",
    "The torch.nn.functional area specifically gives us access to some handy functions that we might not want to write ourselves. We will be using the relu or \"rectified linear\" activation function for our neurons. Instead of writing all of the code for these things, we can just import them, since these are things everyone will be needing in their deep learning code.\n",
    "\n",
    "If you wish to learn about how to write those things, keep your eyes peeled for a neural network from scratch tutorial.\n",
    "\n",
    "To make our model, we're going to create a class. We'll call this class net and this net will inhereit from the nn.Module class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing b\n"
     ]
    }
   ],
   "source": [
    "class a:\n",
    "    '''Will be a parent class'''\n",
    "    def __init__(self):\n",
    "        print(\"initializing a\")\n",
    "\n",
    "class b(a):\n",
    "    '''Inherits from a, but does not run a's init method '''\n",
    "    def __init__(self):\n",
    "        print(\"initializing b\")\n",
    "\n",
    "class c(a):\n",
    "    '''Inhereits from a, but DOES run a's init method'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"initializing c\")\n",
    "\n",
    "b_ob = b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing a\n",
      "initializing c\n"
     ]
    }
   ],
   "source": [
    "c_ob = c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we're doing is just defining values for some layers, we're calling them fc1, fc2...etc, but you could call them whatever you wanted. The fc just stands for fully connected. Fully connected refers to the point that every neuron in this layer is going to be fully connected to attaching neurons. Nothing fancy going on here! Recall, each \"connection\" comes with weights and possibly biases, so each connection is a \"parameter\" for the neural network to play with.\n",
    "\n",
    "In our case, we have 4 layers. Each of our nn.Linear layers expects the first parameter to be the input size, and the 2nd parameter is the output size.\n",
    "\n",
    "So, our first layer takes in 28x28, because our images are 28x28 images of hand-drawn digits. A basic neural network is going to expect to have a flattened array, so not a 28x28, but instead a 1x784.\n",
    "\n",
    "Then this outputs 64 connections. This means the next layer, fc2 takes in 64 (the next layer is always going to accept however many connections the previous layer outputs). From here, this layer ouputs 64, then fc3 just does the same thing.\n",
    "\n",
    "fc4 takes in 64, but outputs 10. Why 10? Our \"output\" layer needs 10 neurons. Why 10 neurons? We have 10 classes.\n",
    "\n",
    "Now, that's great, we have those layers, but nothing really dictating how they interact with eachother, they're just simply defined.\n",
    "\n",
    "The simplest neural network is fully connected, and feed-forward, meaning we go from input to output. In one side and out the other in a \"forward\" manner. We do not have to do this, but, for this model, we will. So let's define a new method for this network called forward and then dictate how our data will pass through this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((28,28))\n",
    "X = X.view(1,28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3921e-01,  6.0459e-01, -7.1354e-02, -5.3037e-01, -9.6750e-01,\n",
       "          4.3706e-01,  6.4271e-01, -4.5614e-01,  2.7999e-01, -1.1592e+00,\n",
       "          1.2905e+00, -8.3107e-01,  2.6175e-01,  1.0125e+00,  7.6001e-01,\n",
       "          2.2098e+00, -1.2968e+00,  7.7191e-01,  1.5508e-01, -4.5879e-01,\n",
       "         -7.3078e-02,  2.5715e-01, -1.4791e+00,  1.4386e+00, -6.8889e-01,\n",
       "          4.8600e-01, -5.2128e-01,  1.6282e-01, -3.1453e-01,  3.0997e-01,\n",
       "         -1.0359e+00,  6.3585e-01, -2.4402e-01, -1.7737e+00, -7.3454e-02,\n",
       "         -7.7227e-01,  6.6589e-02,  1.6685e+00,  2.9934e-01, -1.7126e+00,\n",
       "          3.2949e-01,  1.9297e+00,  9.3294e-01, -1.6818e+00,  1.3527e-01,\n",
       "          1.9030e+00,  2.4102e+00,  4.7415e-01, -5.1598e-01,  1.3860e+00,\n",
       "          9.0688e-01,  7.5869e-02,  9.6084e-01,  4.8678e-01, -7.1458e-01,\n",
       "         -1.2259e+00,  2.8310e-02,  3.4644e-01,  2.8503e-01, -1.9093e+00,\n",
       "         -2.0819e-01, -1.6413e-01, -7.4862e-01, -6.9157e-01, -3.4856e-02,\n",
       "          2.8256e-01,  2.4093e-01,  4.8947e-01, -7.7062e-01, -4.2882e-01,\n",
       "          8.3637e-01, -3.1548e-01, -1.0598e+00,  8.1521e-01, -4.8391e-01,\n",
       "         -3.1473e-01,  5.2054e-01, -1.7933e+00,  1.3487e+00, -1.1984e+00,\n",
       "          1.1074e+00,  1.1155e+00, -6.9741e-01,  1.7044e-01, -8.6453e-01,\n",
       "          9.8111e-01,  1.2072e+00, -2.4563e-01,  3.2578e-01, -1.8335e-01,\n",
       "         -3.3334e+00, -4.7253e-01,  1.4092e+00,  2.1563e-01, -8.9299e-01,\n",
       "          4.8362e-01, -4.9819e-01,  1.7471e-01, -4.1799e-01,  8.8243e-01,\n",
       "          2.3082e+00, -7.2399e-01,  1.1130e+00,  2.1710e+00,  8.5368e-02,\n",
       "          1.7767e+00, -5.1176e-01,  8.9391e-02,  2.1904e+00,  5.8722e-01,\n",
       "          1.8009e+00,  1.9044e+00, -2.9357e-01,  1.5095e+00, -7.9977e-01,\n",
       "         -2.9703e-01,  1.1436e+00,  2.2974e+00,  1.6006e+00,  2.4037e-01,\n",
       "          4.3241e-01, -3.7145e-01, -4.0814e-01,  4.6505e-01,  1.9428e+00,\n",
       "         -5.9842e-03,  1.7481e+00,  6.0041e-01, -2.4388e+00, -1.0426e+00,\n",
       "         -1.8873e+00,  1.3797e+00, -5.0037e-01, -4.9570e-01, -5.3940e-02,\n",
       "         -1.1465e+00,  3.6465e-01, -7.8562e-01,  9.2698e-01, -7.3994e-01,\n",
       "         -9.5354e-01, -2.6784e-01, -3.9347e-01, -7.3619e-02, -9.9236e-01,\n",
       "          7.3217e-01,  1.2456e+00, -1.4519e-01,  1.8419e-01,  7.9982e-01,\n",
       "         -1.1648e-01,  7.5974e-01, -1.9947e-02, -1.1369e-01, -4.9323e-01,\n",
       "         -4.6356e-02,  5.5277e-01,  1.2008e+00, -9.8911e-01, -1.0639e+00,\n",
       "         -1.7535e-01,  1.3679e-01, -6.3918e-02, -4.7950e-01,  1.8330e+00,\n",
       "          4.6803e-01,  1.7245e+00,  6.6362e-01,  1.6480e-01, -1.8166e+00,\n",
       "         -3.9890e-01,  6.1038e-01, -1.2925e+00,  3.1226e-01,  8.8582e-01,\n",
       "          1.4987e+00,  2.3565e+00,  6.6026e-01,  6.3726e-01,  3.7023e-01,\n",
       "          6.9799e-01,  1.7874e+00, -1.1409e+00,  7.4841e-01,  1.7009e+00,\n",
       "          1.7931e+00,  4.7427e-01, -1.7354e+00,  6.7015e-02,  1.0427e+00,\n",
       "          8.5179e-02, -6.6247e-01, -1.1899e+00,  3.4819e-01, -1.3245e+00,\n",
       "         -1.7957e+00,  4.2170e-01,  1.6419e+00, -6.1655e-01,  1.2794e+00,\n",
       "          1.2878e-01, -4.3404e-01, -1.1657e-01,  7.7640e-01,  1.4565e+00,\n",
       "         -1.4631e+00, -5.9900e-01, -9.5953e-01,  5.4206e-01, -3.9018e-01,\n",
       "         -1.5212e+00,  1.2150e+00, -1.3978e+00,  5.2638e-01, -1.8002e+00,\n",
       "          9.2032e-01, -1.3649e-01, -1.1235e+00,  1.0228e+00,  8.5312e-01,\n",
       "         -2.1204e-01, -8.8417e-02,  5.8189e-01,  1.7900e+00, -8.3614e-01,\n",
       "         -1.5549e+00, -7.6175e-01,  8.7378e-01, -8.0370e-01,  2.7430e-01,\n",
       "         -1.0287e+00, -1.3381e+00,  3.5061e+00, -5.2247e-01,  8.5793e-01,\n",
       "         -1.6669e+00, -2.8473e-01,  8.1040e-01, -7.7411e-01,  1.3617e+00,\n",
       "          2.4262e-01, -8.9690e-01,  4.7882e-01,  1.8108e+00,  1.5925e+00,\n",
       "          1.8209e+00,  4.2691e-01, -4.4815e-01,  2.1394e+00, -3.6009e-01,\n",
       "          6.5376e-01, -5.5147e-01,  1.1348e+00, -1.9203e-01,  1.1206e+00,\n",
       "         -2.0138e-01, -1.2646e+00,  2.2810e+00, -1.1235e-01,  2.0799e+00,\n",
       "         -1.1920e+00, -5.9493e-01,  1.0006e+00, -9.5693e-01,  1.1822e+00,\n",
       "          5.8088e-02, -4.5090e-01, -1.7003e+00,  1.5211e-01, -4.1317e-01,\n",
       "          7.2916e-01,  7.0921e-01, -9.4635e-01,  3.5312e-01,  1.2861e+00,\n",
       "         -1.0465e+00, -1.2789e+00,  8.1940e-01,  5.8582e-01,  3.1142e-01,\n",
       "         -5.0478e-01,  6.7146e-02, -1.3446e-01, -5.1712e-01,  6.7775e-01,\n",
       "          4.4093e-01,  9.5783e-02, -7.6728e-01,  8.3612e-01,  1.4130e+00,\n",
       "          1.4251e+00, -2.3444e-01, -6.2380e-02,  1.7277e+00,  4.4950e-01,\n",
       "          1.0100e-01, -4.2650e-01,  8.5353e-01,  8.8729e-01, -7.2413e-01,\n",
       "          1.7388e+00, -1.2987e-01,  4.8731e-02, -8.1012e-01, -3.2128e-01,\n",
       "         -5.5645e-01,  1.0135e+00,  9.1423e-03, -6.5787e-01,  5.1449e-01,\n",
       "          5.9426e-01,  2.1036e-01,  3.3683e-01, -4.1524e-01,  9.3190e-02,\n",
       "         -6.5318e-01,  1.9603e+00, -5.5770e-01, -4.2185e-01,  1.2418e+00,\n",
       "          8.6041e-01,  1.7975e-01,  4.6508e-01,  1.8081e+00,  3.8647e-01,\n",
       "          1.0233e+00, -6.3863e-01, -5.2371e-01, -2.6419e-01,  2.4205e-01,\n",
       "          1.2764e+00,  4.2550e-01, -4.2092e-01,  4.3543e-01,  3.1222e-01,\n",
       "          6.0602e-01,  3.8199e-02, -9.3973e-01,  9.1758e-01, -4.6029e-01,\n",
       "          4.2459e-01, -5.4489e-01, -6.7952e-01, -4.0900e+00,  2.8641e+00,\n",
       "          3.7377e-01,  2.8275e-01, -1.6329e+00, -1.0586e-01,  1.6659e+00,\n",
       "          1.0611e+00, -1.6484e+00, -1.0340e+00, -1.2392e+00, -4.0188e-01,\n",
       "          1.0690e+00, -1.0289e+00,  5.7906e-01,  2.4084e-01,  7.1651e-01,\n",
       "          1.2736e-01,  5.9972e-01, -1.7977e+00,  1.6733e+00,  2.0702e-01,\n",
       "          1.8042e-01, -3.3005e-01,  2.4162e-01, -3.1779e-02, -2.6263e+00,\n",
       "          1.2514e+00,  6.7495e-01,  3.4530e-01, -1.8738e-01, -8.1216e-01,\n",
       "          8.1680e-02, -6.7503e-01,  1.7857e-01,  4.8318e-01,  1.6668e+00,\n",
       "         -2.8604e-01,  1.4365e+00, -1.0326e-01,  3.8976e-01,  3.2771e-01,\n",
       "         -6.8377e-01, -1.7497e+00,  1.2745e+00,  2.8061e-01, -1.5713e+00,\n",
       "         -1.9796e+00, -1.2517e-01, -1.3894e+00,  1.0436e+00,  7.4333e-01,\n",
       "         -1.2366e+00,  6.6649e-01, -1.0400e+00,  3.9401e-01, -6.7203e-01,\n",
       "          7.7630e-01,  6.0591e-02,  1.3705e+00,  1.1730e+00, -6.9489e-01,\n",
       "          7.1169e-01,  5.1940e-03, -5.1400e-01, -1.2208e+00,  7.9553e-01,\n",
       "          1.6638e-01, -9.2909e-01, -1.3180e+00,  3.1680e-01,  2.5004e-02,\n",
       "          1.6118e+00,  2.8011e+00,  2.1667e-01, -2.3213e-01, -2.8720e-01,\n",
       "          5.0171e-01,  3.9726e-01,  3.1943e-01, -1.3312e+00, -7.1718e-01,\n",
       "          3.2588e-01, -6.0790e-01, -7.0339e-01,  1.3435e+00, -1.0646e+00,\n",
       "          2.8001e-01,  2.1136e-01,  3.1313e+00,  3.8645e-02,  5.3709e-01,\n",
       "          6.7807e-02, -4.8362e-01,  7.8408e-02,  1.2983e+00,  9.9291e-01,\n",
       "          5.5838e-01, -5.4672e-01, -1.7887e+00, -1.4673e+00,  8.5389e-01,\n",
       "         -4.8882e-01,  1.0835e+00, -1.4717e+00,  8.7822e-02, -3.5278e-01,\n",
       "         -1.5551e+00, -1.0910e+00,  1.4939e+00,  8.1435e-01, -8.8958e-02,\n",
       "         -1.3859e+00, -1.1103e+00,  7.2755e-01,  1.0140e+00, -5.2657e-01,\n",
       "          1.8436e-01, -4.9144e-01, -3.6137e-01, -4.1106e-02,  5.0196e-01,\n",
       "          9.3592e-01, -6.9676e-01, -7.0222e-01,  3.1997e-01, -3.0265e-01,\n",
       "          1.5860e-01, -7.3200e-01,  7.5917e-01,  2.6530e-01,  7.5922e-01,\n",
       "         -2.7120e-01, -1.6884e-01,  1.2623e-01, -1.3331e+00, -3.8920e-01,\n",
       "         -2.2658e-01, -4.9588e-01, -8.6436e-01,  4.1018e-01, -4.5117e-02,\n",
       "         -1.9809e-01,  1.1787e+00, -9.5996e-01, -1.7634e+00, -2.2465e-02,\n",
       "          2.1746e+00,  8.2072e-01,  1.3409e+00, -9.4130e-01,  1.5012e-01,\n",
       "         -7.6197e-01,  1.0510e+00,  2.1585e-01, -7.7805e-01,  1.0342e+00,\n",
       "         -1.0444e+00,  6.5668e-01,  7.2289e-01, -8.3181e-01, -1.2244e+00,\n",
       "          1.6075e+00, -1.3959e-01, -2.0935e-01, -6.1885e-01,  1.2257e-01,\n",
       "         -1.4389e+00, -1.5528e-01,  1.9188e+00,  1.7161e-01,  7.7099e-01,\n",
       "          1.2911e+00, -1.8236e-01,  3.0965e-01,  5.7532e-01, -6.5056e-01,\n",
       "         -6.5759e-01,  1.3365e+00, -3.6239e-01,  7.1708e-01,  1.6563e+00,\n",
       "         -5.7258e-01,  9.3425e-01, -1.3720e+00,  9.1929e-01,  1.0373e-01,\n",
       "          2.1671e-01,  9.7461e-01,  8.6901e-01, -1.5885e+00,  2.4247e+00,\n",
       "          1.8397e-01,  1.5979e+00, -6.8939e-01,  2.2446e-01,  8.2739e-01,\n",
       "         -4.2505e-01, -1.8432e+00,  4.8022e-01, -1.0862e+00,  1.2239e+00,\n",
       "          5.0825e-01,  2.8501e-02, -1.0850e-01, -2.1464e+00,  1.1433e+00,\n",
       "          3.1177e-01, -1.7175e-01,  1.9374e+00,  6.8000e-01,  5.4845e-01,\n",
       "         -7.1464e-01, -1.1288e+00, -5.1834e-01,  9.8820e-01,  1.1179e+00,\n",
       "         -4.7751e-01,  2.9835e-01, -1.8542e-01, -1.8501e-01,  1.2885e+00,\n",
       "         -8.0732e-02,  9.2711e-01,  9.2080e-01, -6.2291e-02,  1.0957e+00,\n",
       "         -1.6989e+00,  1.4689e+00,  2.0732e-01, -5.0114e-01,  1.1164e+00,\n",
       "         -2.7160e-01,  5.1224e-01,  8.9718e-01,  1.3917e+00, -4.6001e-01,\n",
       "         -4.9221e-01, -2.0557e-01, -1.3658e-01, -8.4199e-01, -3.1308e-01,\n",
       "         -2.7719e-01,  8.6369e-01, -2.9195e+00, -1.8624e+00, -1.2198e+00,\n",
       "          5.1958e-01, -4.9926e-01,  6.9938e-01, -1.2492e+00, -3.2431e-01,\n",
       "          7.1204e-01, -1.4974e+00, -1.2799e+00, -7.3152e-01,  1.4447e+00,\n",
       "         -1.0988e+00,  1.7446e-01,  3.3941e-01,  1.3581e+00, -1.2956e+00,\n",
       "         -4.5687e-01,  1.5841e+00,  2.2813e-01,  1.0490e-01,  3.7000e-01,\n",
       "          2.4001e-01,  1.4556e+00, -1.5085e-01, -2.1374e-01,  2.5223e-02,\n",
       "          1.7887e+00, -6.4939e-01,  1.4416e+00, -2.7624e-01,  6.0928e-01,\n",
       "         -2.0652e+00, -1.1826e+00,  2.1162e+00,  1.4404e+00,  8.7849e-01,\n",
       "          1.3864e-01, -1.2308e+00,  1.2890e+00, -1.9806e-01,  1.3005e+00,\n",
       "         -7.2480e-01, -6.9637e-02,  9.6791e-01, -4.1560e-01, -5.8265e-01,\n",
       "         -1.4249e+00,  1.1870e+00, -1.6442e+00, -4.9453e-01, -1.2145e+00,\n",
       "         -9.8879e-01,  7.7250e-01, -1.6494e+00,  3.8259e-01,  2.8138e-01,\n",
       "         -9.6162e-01, -2.8467e-01,  2.5546e-01, -5.0244e-01,  6.2220e-01,\n",
       "         -1.5079e-01, -3.0998e-01, -2.1149e-01, -1.1018e+00, -1.6148e+00,\n",
       "          2.1640e+00,  2.5721e-01, -6.7888e-01, -1.4496e-01,  8.0120e-01,\n",
       "         -1.0169e+00, -1.3515e+00,  5.2932e-02, -1.5884e-01, -7.8867e-01,\n",
       "          2.6889e-01,  3.6093e-01, -3.7235e-04,  1.3238e+00,  7.4329e-01,\n",
       "          2.0877e+00, -1.9894e-01,  3.2303e-01,  4.0810e-01, -7.6368e-01,\n",
       "         -1.3951e-01, -1.3144e+00,  9.4391e-01,  3.4987e-01,  8.4326e-01,\n",
       "          8.5155e-01,  1.2972e+00, -3.6975e-01, -8.6817e-01, -1.7882e+00,\n",
       "          1.7159e+00, -2.1740e-01, -6.2569e-01,  8.7033e-01,  3.0196e-01,\n",
       "         -2.1049e+00, -2.0533e-02, -4.1325e-01, -1.7387e+00, -7.7605e-01,\n",
       "          1.0301e-01, -5.8696e-01,  1.5848e+00,  2.6577e-01, -5.5044e-02,\n",
       "          3.4443e-01, -2.5311e-01,  2.4527e+00, -2.2986e+00,  1.1082e+00,\n",
       "         -1.1245e+00, -6.5535e-01, -7.3630e-01, -1.0579e-01,  8.3603e-02,\n",
       "         -2.1381e+00,  1.6552e-01, -9.4483e-01, -4.6223e-01, -1.3569e+00,\n",
       "         -7.6943e-02, -5.7833e-01, -6.6169e-01, -6.7141e-01, -1.6579e-01,\n",
       "          8.1044e-01,  1.4627e+00, -1.9262e+00,  8.5353e-01,  3.0787e-01,\n",
       "          8.5478e-02, -9.8042e-01, -1.0460e+00, -5.8319e-01,  2.0425e+00,\n",
       "         -1.1002e+00, -9.3411e-01, -8.9094e-02,  2.1847e+00, -7.2386e-01,\n",
       "          1.0184e-01, -6.2517e-01, -1.8489e+00, -6.7838e-01,  7.2782e-01,\n",
       "          6.7596e-01,  1.3541e+00, -2.7826e+00, -2.1165e-01,  1.3993e+00,\n",
       "         -1.5447e-02, -8.7686e-01,  3.5738e-01,  6.4988e-01, -3.4943e-01,\n",
       "          2.3618e-01, -8.8107e-01, -2.4060e-01, -7.6189e-01,  1.0234e-01,\n",
       "          3.2390e-02, -6.3483e-01, -6.3724e-02,  7.6096e-01, -2.0554e+00,\n",
       "          8.3627e-02, -5.5405e-01, -6.4785e-01, -6.5268e-01, -7.2007e-01,\n",
       "         -3.7436e-01, -5.8733e-01,  1.5433e+00,  1.0036e+00, -1.7623e-02,\n",
       "         -4.0427e-01,  1.2885e+00, -4.2861e-01,  7.5898e-01, -7.8855e-01,\n",
       "         -1.0331e-01,  4.2604e-01,  1.3783e+00, -1.7324e+00, -6.4377e-01,\n",
       "         -6.5230e-01,  4.6520e-01,  5.0438e-03,  6.3822e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2787, -2.3532, -2.3873, -2.2256, -2.3054, -2.4224, -2.2334, -2.2393,\n",
       "         -2.3433, -2.2584]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
