{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=40, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=40, shuffle=False)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us, the \"data\" that we're using from Pytorch is actually nice fancy object that is making life easy for us at the moment. It's already in pretty batches and we just need to iterate over it. Next, we want to calculate loss and specify our optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loss_function is what calculates \"how far off\" our classifications are from reality. As humans, we tend to think of things in terms of either right, or wrong. With a neural network, and arguably humans too, our accuracy is actually some sort of scaling score.\n",
    "\n",
    "For example, you might be highly confident that something is the case, but you are wrong. Compare this to a time when you really aren't certain either way, but maybe think something, but are wrong. In these cases, the degree to which you're wrong doesn't matter in terms of the choice necessarily, but in terms of you learning, it does.\n",
    "\n",
    "In terms of a machine learning by tweaking lots of little parameters to slowly get closer and closer to fitting, it definitely matters how wrong things are.\n",
    "\n",
    "For this, we use loss, which is a measurement of how far off the neural network is from the targeted output. There are a few types of loss calculations. A popular one is mean squared error, but we're trying to use these scalar-valued classes.\n",
    "\n",
    "In general, you're going to have two types of classes. One will just be a scalar value, the other is what's called a one_hot array/vector.\n",
    "\n",
    "In our case, a zero might be classified as:\n",
    "\n",
    "0 or [1, 0, 0, 0, 0, 0, 0 ,0 ,0 ,0]\n",
    "\n",
    "[1, 0, 0, 0, 0, 0, 0 ,0 ,0 ,0] is a one_hot array where quite literally one element only is a 1 and the rest are zero. The index that is hot is the classification.\n",
    "\n",
    "A one_hot vector for a a 3 would be:\n",
    "\n",
    "[0, 0, 0, 1, 0, 0, 0 ,0 ,0 ,0]\n",
    "\n",
    "I tend to use one_hot, but this data is specifying a scalar class, so 0, or 1, or 2...and so on.\n",
    "\n",
    "Depending on what your targets look like, you will need a specific loss.\n",
    "\n",
    "For one_hot vectors, I tend to use mean squared error.\n",
    "\n",
    "For these scalar classifications, I use cross entropy.\n",
    "\n",
    "Next, we have our optimizer. This is the thing that adjusts our model's adjustable parameters like the weights, to slowly, over time, fit our data. I am going to have us using Adam, which is Adaptive Momentum. This is the standard go-to optimizer usually. There's a new one called rectified adam that is gaining steam. I haven't had the chance yet to make use of that in any project, and I do not think it's available as just an importable function in Pytorch yet, but keep your eyes peeled for it! For now, Adam will do just fine I'm sure. The other thing here is lr, which is the learning rate. A good number to start with here is 0.001 or 1e-3. The learning rate dictates the magnitude of changes that the optimizer can make at a time. Thus, the larger the LR, the quicker the model can learn, but also you might find that the steps you allow the optimizer to make are actually too big and the optimizer gets stuck bouncing around rather than improving. Too small, and the model can take much longer to learn as well as also possibly getting stuck.\n",
    "\n",
    "Imagine the learning rate as the \"size of steps\" that the optimizer can take as it searches for the bottom of a mountain, where the path to the bottom isn't necessarily a simple straight path down. Here's some lovely imagery to help explain learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2029, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0484, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1895, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of data\n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every line here is commented, but the concept of gradients might not be clear. Once we pass data through our neural network, getting an output, we can compare that output to the desired output. With this, we can compute the gradients for each parameter, which our optimizer (Adam, SGD...etc) uses as information for updating weights.\n",
    "\n",
    "This is why it's important to do a net.zero_grad() for every step, otherwise these gradients will add up for every pass, and then we'll be re-optimizing for previous gradients that we already optimized for. There could be times when you intend to have the gradients sum per pass, like maybe you have a batch of 10, but you want to optimize per 50 or something. I don't think people really do that, but the idea of Pytorch is to let you do whatever you want.\n",
    "\n",
    "So, for each epoch, and for each batch in our dataset, what do we do?\n",
    "\n",
    "Grab the features (X) and labels (y) from current batch\n",
    "Zero the gradients (net.zero_grad)\n",
    "Pass the data through the network\n",
    "Calculate the loss\n",
    "Adjust weights in the network with the hopes of decreasing loss\n",
    "As we iterate, we get loss, which is an important metric, but we care about accuracy. So, how did we do? To test this, all we need to do is iterate over our test set, measuring for correctness by comparing output to target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.967\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.9439e+01, -1.6086e+01, -1.3590e+01, -1.9691e+01, -4.7087e-05,\n",
      "        -1.2413e+01, -1.8004e+01, -1.1138e+01, -1.6696e+01, -1.0517e+01],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "a_featureset = X[0]\n",
    "reshaped_for_network = a_featureset.view(-1,784) # 784 b/c 28*28 image resolution.\n",
    "output = net(reshaped_for_network) #output will be a list of network predictions.\n",
    "first_pred = output[0]\n",
    "print(first_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "biggest_index = torch.argmax(first_pred)\n",
    "print(biggest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
